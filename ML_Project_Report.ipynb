{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9f84670103f567",
   "metadata": {},
   "source": [
    "<b>\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"5\">\n",
    "Predicting Age from Images Using Deep Neural Network\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Abhilasha Singh\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Project Report\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Data Science, Columbian College of Arts & Sciences, George Washington University\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Yuxiao Huang\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb10c37d12b3dc1",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\">\n",
    "  <ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li>\n",
    "    <li><span><a href=\"#Dataset-Overview\" data-toc-modified-id=\"Dataset-Overview-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset Overview</a></span></li>\n",
    "    <li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preprocessing</a></span></li>\n",
    "    <li><span><a href=\"#Data-Augmentation-and-Transforms\" data-toc-modified-id=\"Data-Augmentation-and-Transforms-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Augmentation and Transforms</a></span></li>\n",
    "    <li><span><a href=\"#Model-Architectures\" data-toc-modified-id=\"Model-Architectures-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Architectures</a></span></li>\n",
    "    <li><span><a href=\"#Training-and-Validation\" data-toc-modified-id=\"Training-and-Validation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training and Validation</a></span></li>\n",
    "    <li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cross-Validation</a></span></li>\n",
    "    <li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Visualizations</a></span></li>\n",
    "    <li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Hyperparameter Tuning</a></span></li>\n",
    "    <li><span><a href=\"#Result\" data-toc-modified-id=\"Result-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Result</a></span></li>\n",
    "    <li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Conclusion</a></span></li>\n",
    "    <li><span><a href=\"#References\" data-toc-modified-id=\"References-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>References</a></span></li>\n",
    "    <li><span><a href=\"#Video-Link\" data-toc-modified-id=\"Video-Link-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Video Link</a></span></li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba15f2c2f78b32",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bcaa9d0935d94",
   "metadata": {},
   "source": [
    "Predicting a person’s age from a single facial image has significant real-world applications, including early health diagnostics, identity verification, and personalized marketing. While humans rely on general visual impressions to estimate age, deep learning models can identify fine-grained patterns such as skin texture, facial symmetry, and hair features,that are not easily perceptible to the human eye.\n",
    "\n",
    "This project aims to build an accurate deep learning-based age prediction model using facial images. We developed the model in PyTorch, starting with a cleaned dataset by filtering out low-quality and unreliable samples. To improve performance and generalization, we employed a pretrained ResNet architecture alongside data augmentation, early stopping, and adaptive learning rate scheduling. We further enhanced model robustness through cross-validation and hyperparameter tuning. Our final model achieved an RMSE of approximately 7, demonstrating strong predictive accuracy on real-world image data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1ede708eb8871",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4731f01845831",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Source**:  Kaggle-*Age Prediction (Spring '25 @ CU Denver)*\n",
    "\n",
    "**Total Size**: 323.57 MB\n",
    "\n",
    "**Total Files**: 61,741\n",
    "\n",
    "This project utilizes the following dataset components:\n",
    "\n",
    "- **wiki_labels.csv**: Contains total 11 columns for facial images including ID,Photo taken date,Labeled ages (target variable),Gender,Face detection confidence scores (face_score),full image paths and others.\n",
    "\n",
    "- **wiki_judge.csv**: Includes total 5 columns including ID,Full file path,Gender,face_score and second_face_score\n",
    "  - Note: Age labels are not included in this file\n",
    "\n",
    "- **wiki_labeled/**: A directory containing 60,327 facial images across 100 folders (00 to 99).Each image is standardized to a resolution of 100×100 pixels.\n",
    "\n",
    "- **wiki_judge_images/**: Contains 1,409 additional facial images (e.g., 1.png, 2.png, etc.),also with a resolution of 100×100 pixels.\n",
    "\n",
    "Objective\n",
    "\n",
    "Develop a predictive model, defined as:  f(image) → age,  that estimates a person's age from a single facial image.The model’s performance is evaluated using the **Root Mean Squared Error (RMSE)** between predicted and actual age values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513adbdfda0d7c09",
   "metadata": {},
   "source": [
    "## Data Preprocessing ##\n",
    "\n",
    "Ensuring the quality of the training data was essential for achieving robust model performance. The following preprocessing steps were implemented to clean and prepare the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f953f6c16a492ed",
   "metadata": {},
   "source": [
    "#### Data Loading ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856170ecda05ae33",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully set up at: C:\\Users\\HP\\kaggle_data\\extracted\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Data location: C:\\Users\\HP\\kaggle_data\\extracted\n",
      "\n",
      "First few rows of data:\n",
      "     ID     dob          dob_str  photo_taken  \\\n",
      "0  2002  723671  ['05-May-1981']         2009   \n",
      "1  2003  711677  ['03-Jul-1948']         2008   \n",
      "2  2004  705061  ['23-May-1930']         1961   \n",
      "3  2005  720044  ['31-May-1971']         2012   \n",
      "4  2006  716189  ['09-Nov-1960']         2012   \n",
      "\n",
      "                             full_path  gender                      name  \\\n",
      "0  ['17/10000217_1981-05-05_2009.png']     1.0       ['Sami Jauhojärvi']   \n",
      "1    ['12/100012_1948-07-03_2008.png']     1.0           ['Marc Okrand']   \n",
      "2  ['65/10001965_1930-05-23_1961.png']     1.0  ['Aleksandar Matanović']   \n",
      "3  ['16/10002116_1971-05-31_2012.png']     0.0          ['Diana Damrau']   \n",
      "4  ['02/10002702_1960-11-09_2012.png']     0.0        ['Krista Tippett']   \n",
      "\n",
      "                                       face_location   face_score  \\\n",
      "0  [[111.29109473 111.29109473 252.66993082 252.6...  4.300962388   \n",
      "1                    [[113.52 169.84 366.08 422.4 ]]  4.329328832   \n",
      "2                                [[  1   1 634 440]]       #NAME?   \n",
      "3  [[171.61031405  75.5745124  266.76611571 170.7...  3.408442415   \n",
      "4  [[274.7656324   57.77009008 376.88699455 159.8...  4.748056378   \n",
      "\n",
      "   second_face_score        age  \n",
      "0                NaN  27.746119  \n",
      "1                NaN  59.582192  \n",
      "2                NaN  30.696804  \n",
      "3                NaN  40.672146  \n",
      "4                NaN  51.224201  \n",
      "Dataset successfully set up at: C:\\Users\\HP\\kaggle_data\\extracted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import zipfile\n",
    "import subprocess\n",
    "import shutil\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def setup_kaggle_dataset(\n",
    "        competition_name: str = \"age-prediction-spring-25-at-cu-denver\",\n",
    "        data_dir: str = \"kaggle_data\",\n",
    "        force_redownload: bool = False\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Download and extract Kaggle competition dataset, returning the root path.\n",
    "    Ensures Kaggle API is set up and dataset is extracted to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        competition_name: Name of the Kaggle competition\n",
    "        data_dir: Directory to store the downloaded data\n",
    "        force_redownload: Whether to force re-download even if files exist\n",
    "\n",
    "    Returns:\n",
    "        Path to the root directory of extracted dataset\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If any step in the process fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up paths\n",
    "        data_path = Path(data_dir).resolve()\n",
    "        zip_file = data_path / f\"{competition_name}.zip\"\n",
    "        extract_path = data_path / \"extracted\"\n",
    "\n",
    "        # Ensure Kaggle API is available\n",
    "        if not shutil.which(\"kaggle\"):\n",
    "            raise RuntimeError(\"Kaggle CLI not found. Please install with: pip install kaggle\")\n",
    "\n",
    "        # Check API credentials\n",
    "        kaggle_json_path = Path.home() / \".kaggle/kaggle.json\"\n",
    "        if not kaggle_json_path.exists():\n",
    "            raise RuntimeError(\n",
    "                \"Kaggle API key not found. Please set up your Kaggle API by:\\n\"\n",
    "                \"1. Going to https://www.kaggle.com/<your-username>/account\\n\"\n",
    "                \"2. Clicking 'Create New API Token'\\n\"\n",
    "                \"3. Moving kaggle.json to ~/.kaggle/\\n\"\n",
    "                \"4. Running: chmod 600 ~/.kaggle/kaggle.json\"\n",
    "            )\n",
    "\n",
    "        # Create data directory\n",
    "        data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Download dataset\n",
    "        if force_redownload or not zip_file.exists():\n",
    "            print(f\"Downloading dataset from Kaggle: {competition_name}\")\n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    [\"kaggle\", \"competitions\", \"download\", \"-c\", competition_name, \"-p\", str(data_path)],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    text=True\n",
    "                )\n",
    "                if result.returncode != 0:\n",
    "                    raise RuntimeError(f\"Kaggle download failed: {result.stderr}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                raise RuntimeError(f\"Failed to download dataset: {e.stderr}\")\n",
    "\n",
    "        # Extract dataset\n",
    "        if force_redownload or not extract_path.exists():\n",
    "            print(f\"Extracting dataset to {extract_path}\")\n",
    "            try:\n",
    "                with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(extract_path)\n",
    "            except zipfile.BadZipFile:\n",
    "                print(\"Corrupted zip file detected. Deleting and re-downloading...\")\n",
    "                zip_file.unlink()\n",
    "                return setup_kaggle_dataset(competition_name, data_dir, force_redownload=True)\n",
    "\n",
    "        # Find the root path containing our data files\n",
    "        root_path = find_dataset_root(extract_path)\n",
    "\n",
    "        # Verify we found the important files\n",
    "        verify_dataset_files(root_path)\n",
    "\n",
    "        print(f\"Dataset successfully set up at: {root_path}\")\n",
    "        return root_path\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to set up dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def find_dataset_root(search_path: Path) -> Path:\n",
    "    \"\"\"Recursively search for the directory containing wiki_labels.csv\"\"\"\n",
    "    for dirpath, _, filenames in os.walk(search_path):\n",
    "        if \"wiki_labels.csv\" in filenames:\n",
    "            return Path(dirpath)\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find wiki_labels.csv in {search_path} or its subdirectories. \"\n",
    "        \"The dataset structure may have changed.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def verify_dataset_files(root_path: Path) -> None:\n",
    "    \"\"\"Verify all expected files and directories exist and are accessible\"\"\"\n",
    "    expected_files = [\"wiki_labels.csv\", \"wiki_judge.csv\", \"sample_submission.csv\"]\n",
    "    expected_dirs = [\n",
    "        \"wiki_labeled/wiki_labeled\",\n",
    "        \"wiki_judge_images/wiki_judge_images\"\n",
    "    ]\n",
    "\n",
    "    # Check files\n",
    "    for file in expected_files:\n",
    "        file_path = root_path / file\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"Required file not found: {file_path}\")\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                f.read(1)  # Test file readability\n",
    "        except IOError as e:\n",
    "            raise IOError(f\"Cannot read file {file_path}: {e}\")\n",
    "\n",
    "    # Check directories\n",
    "    for dir in expected_dirs:\n",
    "        dir_path = root_path / dir\n",
    "        if not dir_path.exists():\n",
    "            raise FileNotFoundError(f\"Required directory not found: {dir_path}\")\n",
    "        if not os.access(dir_path, os.R_OK):\n",
    "            raise PermissionError(f\"Cannot read directory: {dir_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Set up dataset\n",
    "        root = setup_kaggle_dataset()\n",
    "\n",
    "        # Load the main CSV file\n",
    "        csv_path = root / \"wiki_labels.csv\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        print(\"\\nDataset loaded successfully!\")\n",
    "        print(f\"Data location: {root}\")\n",
    "        print(\"\\nFirst few rows of data:\")\n",
    "        print(df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "root = setup_kaggle_dataset()\n",
    "csv_path = root / \"wiki_labels.csv\"\n",
    "image_dir = root / \"wiki_labeled/wiki_labeled\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2002de0c6d1f9bbf",
   "metadata": {},
   "source": [
    "#### Handling Missing Data,Imbalanced Data,Numeric conversion ####\n",
    "\n",
    "##### Gender Balancing\n",
    "\n",
    "The dataset exhibited a substantial gender skew around 45,558 male images compared to just 12,216 female images. To address this imbalance, we applied partial oversampling to the underrepresented class (females) using a factor of 1.8. This adjustment improved class representation while preserving the natural distribution to some extent.\n",
    "\n",
    "The bar plot below illustrates the initial gender distribution across the dataset, clearly showing the dominance of male images and the smaller proportion of female and unknown gender entries. This visualization supports the need for rebalancing during preprocessing.\n",
    "##### Missing and Invalid Data\n",
    "\n",
    "Rows containing missing or corrupt values, such as invalid face_score entries, were excluded from the dataset. This helped maintain data consistency and reduced noise during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b19771544e3d1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "gender_counts = df['gender'].value_counts(dropna=False)\n",
    "labels = ['Female (0)', 'Male (1)', 'Unknown (NaN)']\n",
    "colors = ['green', 'darkblue', 'gray']\n",
    "plt.bar(labels, gender_counts.values, color=colors)\n",
    "plt.title(\"Gender Distribution in Dataset\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37351b8a9d942e0",
   "metadata": {},
   "source": [
    "##### Age Filtering ####\n",
    "\n",
    "To eliminate implausible entries, we filtered the dataset to include only samples where the age fell between 1 and 100. This step helped exclude anomalies such as newborns or excessively high ages, allowing the model to train on realistic age distributions.\n",
    "\n",
    "The boxplot below clearly illustrates the original age distribution, showing several extreme outliers. These outliers were removed as part of the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f938294cd3f5c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(df['age'], vert=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor='blue'))\n",
    "plt.title(\"Age Boxplot\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbb50dad914ea2",
   "metadata": {},
   "source": [
    "##### Face Score Filtering ####\n",
    "\n",
    "The face score column, originally containing some non-numeric values, was converted to a numeric format. We then removed all entries with scores below 1.0, discarding approximately 1,288 low-confidence face detections. This ensured that only clearly identifiable faces were used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "406825de54ae200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully set up at: C:\\Users\\HP\\kaggle_data\\extracted\n",
      "CSV PATH!: C:\\Users\\HP\\kaggle_data\\extracted\\wiki_labels.csv\n",
      "Original dataset size: 60327\n",
      "Cleaned dataset size: 48927\n",
      "Removed 11400 rows.\n",
      "Cleaned CSV saved to C:\\Users\\HP\\kaggle_data\\extracted\\wiki_labels_clean.csv\n",
      "Cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "def balance_by_gender(df, factor=1.8):\n",
    "    df_f = df[df['gender'] == 0.0].copy()\n",
    "    df_m = df[df['gender'] == 1.0].copy()\n",
    "    n_f = len(df_f)\n",
    "    n_m = len(df_m)\n",
    "\n",
    "    if n_f < n_m:\n",
    "        target = int(n_f * factor)\n",
    "        target = min(target, n_m)\n",
    "        df_f_oversampled = df_f.sample(n=target, replace=True)\n",
    "        df_balanced = pd.concat([df_f_oversampled, df_m], ignore_index=True)\n",
    "    else:\n",
    "        target = int(n_m * factor)\n",
    "        target = min(target, n_f)\n",
    "        df_m_oversampled = df_m.sample(n=target, replace=True)\n",
    "        df_balanced = pd.concat([df_f, df_m_oversampled], ignore_index=True)\n",
    "\n",
    "    df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    return df_balanced\n",
    "\n",
    "def clean_dataset(csv_path, output_csv_path=None, min_age=1, max_age=100, min_face_score=1.0, do_balance_gender=True):\n",
    "\n",
    "    print(f\"CSV PATH!: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    original_len = len(df)\n",
    "\n",
    "    df['face_score'] = df['face_score'].replace('#NAME?', np.nan)\n",
    "    df['face_score'] = pd.to_numeric(df['face_score'], errors='coerce')\n",
    "\n",
    "    mask_age = (df['age'] >= min_age) & (df['age'] <= max_age)\n",
    "    mask_face = (df['face_score'].notna()) & (df['face_score'] >= min_face_score)\n",
    "\n",
    "    df = df[mask_age & mask_face].copy()\n",
    "\n",
    "    if do_balance_gender:\n",
    "        df = balance_by_gender(df)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    cleaned_len = len(df)\n",
    "    print(f\"Original dataset size: {original_len}\")\n",
    "    print(f\"Cleaned dataset size: {cleaned_len}\")\n",
    "    print(f\"Removed {original_len - cleaned_len} rows.\")\n",
    "\n",
    "    if output_csv_path is not None:\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Cleaned CSV saved to {output_csv_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    root = setup_kaggle_dataset()\n",
    "    original_csv = root / \"wiki_labels.csv\"\n",
    "    cleaned_csv = root / \"wiki_labels_clean.csv\"\n",
    "\n",
    "    cleaned_df = clean_dataset(\n",
    "        csv_path=original_csv,\n",
    "        output_csv_path=cleaned_csv,\n",
    "        min_age=1,\n",
    "        max_age=100,\n",
    "        min_face_score=1.0,\n",
    "        do_balance_gender=True\n",
    "    )\n",
    "    print(\"Cleaning complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410751771fa63b5",
   "metadata": {},
   "source": [
    "As a result of these preprocessing steps, the final curated dataset consisted of approximately 48,927 high-quality facial images. By applying age and face score thresholds, excluding ambiguous cases with multiple or unclear detections, and addressing gender imbalance, we significantly enhanced the overall integrity of the training data. These refinements played a crucial role in enabling the model to learn more effectively and ultimately improved its predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c4d6580c0f4b72",
   "metadata": {},
   "source": [
    "## Data Augmentation & Transforms ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68578b47cbcfa63a",
   "metadata": {},
   "source": [
    "In To enhance model generalization and reduce overfitting, image augmentations were applied during training. These augmentations simulate real-world variations in facial images, allowing the model to learn more robust features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2f533724e0ab2",
   "metadata": {},
   "source": [
    "####\tTraining Transforms\n",
    "\n",
    "During training, a series of randomized transformations were applied to each image using torchvision.transforms. These include:\n",
    "- Resize to (110, 110) pixels: Ensures input images are consistently sized before augmentation.\n",
    "- Random Rotation (±10°): Introduces slight angular variation to help the model handle tilted faces.\n",
    "- Random Crop to (100, 100): Encourages spatial robustness by slightly shifting the focus area of the face.\n",
    "- Random Horizontal Flip (p=0.5): Mirrors the image with 50% probability to simulate left-right facial orientation changes.\n",
    "- Color Jitter (brightness, contrast, saturation, hue): Simulates lighting and color variations to teach the model color-invariant features.\n",
    "- Gaussian Blur (p=0.1): Randomly applies slight blur to some images, helping the model generalize better to lower-quality inputs.\n",
    "- Normalization: Converts pixel values to a standardized range using ImageNet’s mean and standard deviation for each channel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0de88b8dfe1fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return T.Compose([\n",
    "        T.Resize((110, 110)),\n",
    "        T.RandomRotation(degrees=10),\n",
    "        T.RandomCrop((100, 100)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.03),\n",
    "        T.RandomApply([T.GaussianBlur(kernel_size=3)], p=0.1),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaba147aef32380",
   "metadata": {},
   "source": [
    "####  Validation and Test Transforms\n",
    "\n",
    "For validation and test datasets, deterministic transforms were used to ensure consistency during evaluation:\n",
    "- Resize to (100, 100): All images are resized to a fixed input shape for the model.\n",
    "- Normalization: The same mean and standard deviation values used during training are applied here to ensure the model processes images consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c81288c4bb90355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_transforms():\n",
    "    return T.Compose([\n",
    "        T.Resize((100, 100)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cd6779741852a",
   "metadata": {},
   "source": [
    "These transformations aim to expose the model to diverse visual representations of the same underlying subject (e.g., rotated, cropped, flipped), improving its ability to generalize to unseen data\n",
    "No random augmentations are applied during validation or testing to maintain a fair and repeatable evaluation environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab564da7222a33",
   "metadata": {},
   "source": [
    "## Model Architectures ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b351de166b474597",
   "metadata": {},
   "source": [
    "####  Custom CNN Architecture\n",
    "\n",
    "A compact CNN was developed from scratch to serve as a lightweight and interpretable baseline for age prediction.This model served as an experimental contrast to deeper architectures like ResNet. The architecture is composed of three convolutional blocks followed by fully connected layers:\n",
    "- Convolutional Layers:Capture local visual patterns such as edges, contours, and textures. Each convolution uses a 3x3 kernel with padding to preserve spatial resolution.\n",
    "- Max Pooling:Applied after each convolutional block to downsample spatial dimensions while preserving the most salient features.\n",
    "- Fully Connected Layers:Flattened feature maps are passed through dense layers to produce a continuous age prediction.\n",
    "- ReLU Activation:Introduced after each convolution and dense layer to introduce non-linearity, enabling the model to learn complex patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "599dd8fa56f2cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9bdd7068f2f75c",
   "metadata": {},
   "source": [
    "####  ResNet-50 Based Regressor\n",
    "To improve the model’s ability to learn complex visual features for age prediction, I experimented with several pre-trained convolutional backbones—starting with ResNet-18 and ResNet-34, and ultimately selecting ResNet-50 for its deeper architecture and stronger feature extraction capabilities.\n",
    "\n",
    "The final model builds on ResNet-50, leveraging its pretrained weights and residual connections to produce highly accurate age predictions. Below are the key customizations and enhancements:\n",
    "- Residual Connections: Help combat vanishing gradients and facilitate training of deeper networks by enabling shortcut paths for gradient flow.\n",
    "- Pretrained Weights: Initialized using ImageNet-trained weights, allowing the model to leverage generic visual features such as textures and object parts, which are transferable to age estimation.\n",
    "- Modified Output Head: The original classification head is replaced with:\n",
    "   - Dropout Layer (p = 0.4) to reduce overfitting by randomly disabling neurons during training.\n",
    "   - Fully Connected Layer that outputs a single scalar value corresponding to the predicted age.\n",
    "- Fine-Tuning Strategy: All layers in the network are fine-tuned, allowing the model to fully adapt to the age prediction task using domain-specific facial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b3b71a716306fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RestNet(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super(RestNet, self).__init__()\n",
    "        if pretrained:\n",
    "            weights = ResNet50_Weights.DEFAULT\n",
    "        else:\n",
    "            weights = None\n",
    "\n",
    "        self.model = resnet50(weights=weights)\n",
    "\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(self.model.fc.in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d14f80ed56ca8",
   "metadata": {},
   "source": [
    "## Training and Validation Function ##\n",
    "\n",
    "To train the age prediction models efficiently and robustly, a comprehensive training pipeline was designed. The pipeline incorporates key deep learning best practices such as dynamic learning rate scheduling, early stopping, data augmentation, and validation monitoring.\n",
    "\n",
    "#### Training Strategy\n",
    "- Model Training: The model is trained using the Adam optimizer, which adapts learning rates per parameter and converges faster on non-convex problems like age regression.\n",
    "- Loss Function: We used Smooth L1 Loss (Huber Loss), which combines the benefits of Mean Squared Error (MSE) and Mean Absolute Error (MAE), offering robustness to outliers often present in real-world age data.\n",
    "- Learning Rate Scheduler: ReduceLROnPlateau was implemented to dynamically reduce the learning rate when validation loss stagnates. This helped in escaping shallow local minima and encouraged better convergence in later epochs.\n",
    "- Early Stopping: If the model failed to improve validation RMSE for a specified number of epochs (patience=3), training was halted early to avoid overfitting.\n",
    "\n",
    "#### Validation Process\n",
    "- The dataset was split into training and validation subsets with an 80:20 ratio using random_split.\n",
    "- Both subsets were transformed independently using custom augmentation functions. The validation set was processed without augmentations to reflect real-world performance.\n",
    "- After each epoch, the model was evaluated on the validation set, and key metrics including validation loss, validation RMSE, and learning rate were logged.\n",
    "- Training on 80% of 49k samples is feasible with your batch size (8) and epochs (25).\n",
    "- Validating on 20% 9.8k samples, adds minimal overhead compared to training.\n",
    "- It works seamlessly with cross-validation, early stopping, and augmentations.\n",
    "- If we choose smaller training set then the model sees fewer examples, leading to poorer generalization (higher bias).\n",
    "\n",
    "#### Checkpointing and Logging\n",
    "- The model's parameters were saved whenever a new best validation RMSE was observed.\n",
    "- Logs including epoch-level training/validation loss and RMSE were streamed both to the terminal and saved into a train.log file via Python’s logging module for traceability and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81b747cc42842d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and validation-\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"train.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "def train_model(\n",
    "    csv_path,\n",
    "    img_dir,\n",
    "    epochs=25,\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    checkpoint_path='output/checkpoints/resnet_best.pth',\n",
    "    early_stop_patience=3,\n",
    "    step_size=5,\n",
    "    gamma=0.1\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    full_dataset = AgesDataset(csv_file=csv_path, img_dir=img_dir)\n",
    "    n_total = len(full_dataset)\n",
    "    logger.info(f\"Full dataset size: {n_total}\")\n",
    "\n",
    "    val_split = 0.2\n",
    "    val_size = int(n_total * val_split)\n",
    "    train_size = n_total - val_size\n",
    "\n",
    "    train_subset, val_subset = random_split(full_dataset, [train_size, val_size])\n",
    "    train_subset.dataset.transform = get_train_transforms()\n",
    "    val_subset.dataset.transform = get_val_transforms()\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = RestNet(num_classes=1, pretrained=True).to(device)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "    best_val_rmse = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    best_model_path = os.path.join(os.path.dirname(checkpoint_path), \"temp_best_model.pth\")\n",
    "    os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
    "\n",
    "    # main trainning loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, ages in train_loader:\n",
    "            images = images.to(device)\n",
    "            ages = ages.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).view(-1)\n",
    "            loss = criterion(outputs, ages)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, ages in val_loader:\n",
    "                images = images.to(device)\n",
    "                ages = ages.to(device)\n",
    "                outputs = model(images).view(-1)\n",
    "\n",
    "                loss = criterion(outputs, ages)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                val_preds.extend(outputs.cpu().numpy().tolist())\n",
    "                val_targets.extend(ages.cpu().numpy().tolist())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        mse = mean_squared_error(val_targets, val_preds)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(val_targets, val_preds)\n",
    "        if epoch == epochs - 1 or rmse < best_val_rmse:\n",
    "            y_true = np.array(val_targets) * 100\n",
    "            y_pred = np.array(val_preds) * 100\n",
    "            plot_pred_vs_true(y_true, y_pred, title=f\"[Train_Model] Val RMSE: {rmse:.2f}\")\n",
    "\n",
    "        # updates on training progress at each epoch\n",
    "        logger.info(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f} - Val RMSE: {rmse:.4f} - Val R2: {r2:.4f} - LR: {scheduler.get_last_lr()[0]:.5f}\")\n",
    "\n",
    "\n",
    "        if rmse < best_val_rmse:\n",
    "            best_val_rmse = rmse\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= early_stop_patience:\n",
    "            logger.info(\"Early stopping triggered!\")\n",
    "            break\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    logger.info(f\"Best model (Val RMSE={best_val_rmse:.4f}) saved to {checkpoint_path}\")\n",
    "\n",
    "    return best_val_rmse\n",
    "\n",
    "def train_model_with_validation(\n",
    "    train_csv,\n",
    "    val_csv,\n",
    "    img_dir,\n",
    "    model_class,\n",
    "    epochs=25,\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    checkpoint_path='output/checkpoints/fold.pth',\n",
    "    early_stop_patience=3,\n",
    "    step_size=5,\n",
    "    gamma=0.1\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_dataset = AgesDataset(csv_file=train_csv, img_dir=img_dir)\n",
    "    val_dataset = AgesDataset(csv_file=val_csv,   img_dir=img_dir)\n",
    "\n",
    "    train_dataset.transform = get_train_transforms()\n",
    "    val_dataset.transform   = get_val_transforms()\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = model_class(num_classes=1).to(device)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "    best_val_rmse = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    best_model_path = os.path.join(os.path.dirname(checkpoint_path), \"temp_best_model.pth\")\n",
    "    os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, ages in train_loader:\n",
    "            images = images.to(device)\n",
    "            ages = ages.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).view(-1)\n",
    "            loss = criterion(outputs, ages)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, ages in val_loader:\n",
    "                images = images.to(device)\n",
    "                ages = ages.to(device)\n",
    "                outputs = model(images).view(-1)\n",
    "\n",
    "                loss = criterion(outputs, ages)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                val_preds.extend(outputs.cpu().numpy().tolist())\n",
    "                val_targets.extend(ages.cpu().numpy().tolist())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        mse = mean_squared_error(val_targets, val_preds)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(val_targets, val_preds)\n",
    "        if epoch == epochs - 1 or rmse < best_val_rmse:\n",
    "            y_true = np.array(val_targets) * 100\n",
    "            y_pred = np.array(val_preds) * 100\n",
    "            plot_pred_vs_true(y_true, y_pred, title=f\"[Val] Fold Val RMSE: {rmse:.2f}\")\n",
    "\n",
    "        logger.info(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f} - Val RMSE: {rmse:.4f} - Val R2: {r2:.4f} - LR: {scheduler.get_last_lr()[0]:.5f}\")\n",
    "\n",
    "\n",
    "        # early stop check\n",
    "        if rmse < best_val_rmse:\n",
    "            best_val_rmse = rmse\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= early_stop_patience:\n",
    "            logger.info(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    # load best and return\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    logger.info(f\"Best model (Val RMSE={best_val_rmse:.4f}) saved to {checkpoint_path}\")\n",
    "\n",
    "    return best_val_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752890703152cffb",
   "metadata": {},
   "source": [
    "## Cross-Validation ##\n",
    "\n",
    "To ensure that the model’s performance generalizes effectively and is not influenced by a particular data split, we implemented K-Fold Cross-Validation. This method enhances the reliability of model evaluation by training and validating it across multiple, evenly distributed subsets. Every data point is used once for validation and K-1 times for training, which significantly reduces variance and ensures that the model learns robust patterns. This setup also provides a consistent evaluation framework, especially helpful during hyperparameter tuning or model comparison.\n",
    "\n",
    "- We used KFold(n_splits=5, shuffle=True, random_state=42) from scikit-learn to split the cleaned dataset into 5 stratified folds.\n",
    "- Each fold was divided into training and validation CSV files.\n",
    "- These CSVs were passed to the train_model_with_validation() function for independent training and evaluation.\n",
    "- Checkpoints were saved separately for each fold to monitor individual performances\n",
    "- For each fold, the Root Mean Squared Error (RMSE) on the validation set was calculated and stored.\n",
    "- After training on all folds, the average RMSE across all folds was computed, representing the overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da462e3d4d05d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_training(\n",
    "    csv_path,\n",
    "    img_dir,\n",
    "    model_class,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    epochs=25,\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    checkpoint_root=\"output/checkpoints\",\n",
    "    early_stop_patience=3\n",
    "):\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    n_total = len(df)\n",
    "    logger.info(f\"Total samples in cleaned dataset: {n_total}\")\n",
    "\n",
    "    # split the dataset\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # loop over the folds and train\n",
    "    fold_rmse_list = []\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(np.arange(n_total))):\n",
    "        logger.info(f\"\\nFold {fold_idx+1}/{n_splits}\")\n",
    "\n",
    "        train_df = df.iloc[train_idx].copy().reset_index(drop=True)\n",
    "        val_df   = df.iloc[val_idx].copy().reset_index(drop=True)\n",
    "\n",
    "        train_csv = f\"temp_train_fold{fold_idx}.csv\"\n",
    "        val_csv   = f\"temp_val_fold{fold_idx}.csv\"\n",
    "\n",
    "        train_df.to_csv(train_csv, index=False)\n",
    "        val_df.to_csv(val_csv, index=False)\n",
    "\n",
    "        fold_ckpt_path = f\"{checkpoint_root}/fold_{fold_idx}.pth\"\n",
    "\n",
    "        # now call train_model_with_validation\n",
    "        fold_rmse = train_model_with_validation(\n",
    "            train_csv=train_csv,\n",
    "            val_csv=val_csv,\n",
    "            img_dir=img_dir,\n",
    "            model_class=model_class,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            checkpoint_path=fold_ckpt_path,\n",
    "            early_stop_patience=3,\n",
    "            step_size=5,\n",
    "            gamma=0.1\n",
    "        )\n",
    "\n",
    "        # append the fold rmse to the list\n",
    "        fold_rmse_list.append(fold_rmse)\n",
    "\n",
    "    # this average is the final metric and a much better representation of the model's performance\n",
    "    avg_rmse = np.mean(fold_rmse_list)\n",
    "    logger.info(f\"\\nCross-Validation average RMSE: {avg_rmse:.4f}\")\n",
    "\n",
    "    return avg_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108c544020070be",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "To visually assess the performance of our age prediction model, we implemented a scatter plot function named plot_pred_vs_true(). This function provides a clear visual comparison between the true and predicted age values on the validation set.\n",
    "\n",
    "The plot is instrumental in detecting key model behaviors such as bias trends, signs of underfitting or overfitting, potential data leakage, and the presence of outliers. As a result, it serves as a crucial diagnostic tool within our model evaluation workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46bc6b38b2d2ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_vs_true(y_true, y_pred, title=\"Predicted vs True Ages\", save_path=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.4)\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--', label=\"Perfect Prediction\")\n",
    "    plt.xlabel(\"True Age\")\n",
    "    plt.ylabel(\"Predicted Age\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165cf15d1c25239",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "To optimize the model's performance, we implemented a structured hyperparameter tuning process using a grid search strategy over a predefined search space. For each configuration, we dynamically updated the classification head of a ResNet50 model with the corresponding dropout value and evaluated its performance using 5-fold cross-validation. The model was trained using train_model_with_validation(), and the Root Mean Squared Error (RMSE) from each fold was averaged to gauge overall effectiveness.\n",
    "\n",
    "- Learning Rate (lr): [1e-4, 5e-4]\n",
    "- Batch Size: [32, 64]\n",
    "- Dropout: [0.5]\n",
    "- Epochs: [25]\n",
    "- Early Stop Patience: [2, 3]\n",
    "- Average RMSE across all folds\n",
    "- A custom ResNet50 was used for each configuration with the dropout applied to the final classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d37faa9bfb90bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(cleaned_csv, img_dir, checkpoint_root):\n",
    "    search_space = {\n",
    "        \"lr\": [1e-4,5e-4],\n",
    "        \"batch_size\": [32,64],\n",
    "        \"dropout\": [0.3,0.5],\n",
    "        \"epochs\": [25],\n",
    "        \"early_stop_patience\": [2,3]\n",
    "    }\n",
    "\n",
    "    best_config = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for lr in search_space[\"lr\"]:\n",
    "        for batch_size in search_space[\"batch_size\"]:\n",
    "            for dropout in search_space[\"dropout\"]:\n",
    "                for epochs in search_space[\"epochs\"]:\n",
    "                    for early_stop_patience in search_space[\"early_stop_patience\"]:\n",
    "                        print(\n",
    "                            f\"\\n🔍 Testing config: LR={lr}, BS={batch_size}, DO={dropout}, EPOCHS={epochs}, PATIENCE={early_stop_patience}\")\n",
    "\n",
    "                        # update dropout dynamically in RestNet\n",
    "                        def custom_model(dropout_rate):\n",
    "                            model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "                            model.fc = nn.Sequential(\n",
    "                                nn.Dropout(p=dropout_rate),\n",
    "                                nn.Linear(model.fc.in_features, 1)\n",
    "                            )\n",
    "                            return model\n",
    "\n",
    "                        class TunedResNet(RestNet):\n",
    "                            def __init__(self, num_classes=1):\n",
    "                                super().__init__(num_classes=num_classes)\n",
    "                                self.model = custom_model(dropout)\n",
    "\n",
    "                        avg_rmse = cross_val_training(\n",
    "                            csv_path=str(cleaned_csv),\n",
    "                            img_dir=str(img_dir),\n",
    "                            model_class=TunedResNet,\n",
    "                            n_splits=5,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            lr=lr,\n",
    "                            checkpoint_root=str(checkpoint_root),\n",
    "                            early_stop_patience=early_stop_patience\n",
    "                        )\n",
    "\n",
    "                        if avg_rmse < best_score:\n",
    "                            best_score = avg_rmse\n",
    "                            best_config = {\n",
    "                                \"lr\": lr,\n",
    "                                \"batch_size\": batch_size,\n",
    "                                \"dropout\": dropout,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"early_stop_patience\": early_stop_patience\n",
    "                            }\n",
    "\n",
    "    print(\"\\n✅ Best Hyperparameter Config:\")\n",
    "    print(best_config)\n",
    "    print(f\"Best Avg RMSE: {best_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c61d26749f3785",
   "metadata": {},
   "source": [
    "## Result ##\n",
    "\n",
    "After completing the hyperparameter tuning and training phases, we performed inference on the unseen test set provided in the challenge to evaluate our model's final performance. We used a custom function run_inference_for_report() that loads the best-trained model checkpoint and applies it to the judge/test dataset for age prediction.\n",
    "\n",
    "Two custom PyTorch Dataset classes were defined:\n",
    "\n",
    "- AgesDataset: Used for loading and transforming the training/validation data. It includes logic to parse image paths from the metadata file and filter out invalid or missing image entries.\n",
    "\n",
    "- JudgeDataset: Designed specifically for the test (judge) set. It processes metadata similarly but excludes labels since the ground truth is unavailable. It returns only image tensors and indices for prediction.\n",
    "\n",
    "The model used for final inference is a fine-tuned ResNet50 with a custom classification head. Inference was run on GPU (if available), and predictions were generated in batches using a DataLoader.This process helped us ensure that our model generalizes well to unseen data, and the RMSE achieved during validation served as a reliable proxy for test performance. The final predictions are included in the appendix of the report for reference.\n",
    "\n",
    "The baseline CNN model showed poor results with an RMSE of ~25 and R² of -2.02, indicating severe underfitting. Implementing gender class balancing provided minimal improvement (RMSE ~17), but introducing comprehensive data augmentation techniques—including RGB conversion, resizing, and horizontal flipping—stabilized predictions and reduced RMSE to ~15 (R² 0.05). The transition to ResNet50 marked a major breakthrough, cutting RMSE nearly in half to 9.84 while improving R² to 0.6. Final optimizations—including dropout, batch normalization, Smooth L1 Loss, and hyperparameter tuning—yielded our best results: RMSE of ~7.5 (a 70% reduction from baseline) and R² of 0.79, with train/validation losses converging to ~3 and ~4, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b6bb6f4313635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Starting main pipeline...\n",
      "Dataset successfully set up at: C:\\Users\\HP\\kaggle_data\\extracted\n",
      "🎯 Starting hyperparameter tuning...\n",
      "\n",
      "🔍 Testing config: LR=0.0001, BS=32, DO=0.3, EPOCHS=25, PATIENCE=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 23:04:41,509 [INFO] Total samples in cleaned dataset: 48927\n",
      "2025-04-27 23:04:41,514 [INFO] \n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39141 valid rows  Skipped 0 rows due to missing files.\n",
      "Found 9786 valid rows  Skipped 0 rows due to missing files.\n"
     ]
    }
   ],
   "source": [
    "class AgesDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        def extract_path(raw):\n",
    "            if isinstance(raw, str) and raw.startswith('[') and raw.endswith(']'):\n",
    "                trimmed = raw.strip('[]')\n",
    "                parts = trimmed.split(',')\n",
    "                return parts[0].strip().strip(\"'\").strip('\"')\n",
    "            return raw\n",
    "\n",
    "        valid_rows = []\n",
    "        skipped = 0\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            file_name = extract_path(row['full_path'])\n",
    "            full_path = self.img_dir / file_name\n",
    "            if full_path.exists():\n",
    "                row['full_path'] = file_name\n",
    "                valid_rows.append(row)\n",
    "            else:\n",
    "                skipped += 1\n",
    "\n",
    "        print(f\"Found {len(valid_rows)} valid rows  Skipped {skipped} rows due to missing files.\")\n",
    "        self.data_frame = pd.DataFrame(valid_rows).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data_frame.iloc[idx]\n",
    "        img_path = self.img_dir / row['full_path']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        age = torch.tensor(row['age'], dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, age\n",
    "class JudgeDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, debug=False):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.debug = debug\n",
    "        def extract_path(raw):\n",
    "            if isinstance(raw, str) and raw.startswith('[') and raw.endswith(']'):\n",
    "                trimmed = raw.strip('[]')\n",
    "                parts = trimmed.split(',')\n",
    "                return parts[0].strip().strip(\"'\").strip('\"')\n",
    "            return raw\n",
    "        self.df['full_path'] = self.df['full_path'].apply(extract_path)\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"Judge dataset full paths after extraction:\")\n",
    "            print(self.df['full_path'].head())\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.img_dir / row['full_path']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, idx\n",
    "\n",
    "\n",
    "def run_inference_for_report(judge_csv, judge_img_dir, checkpoint_path):\n",
    "    print(\"📥 Running inference for report evaluation...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = RestNet(num_classes=1, pretrained=False).to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    dataset = JudgeDataset(\n",
    "        csv_file=judge_csv,\n",
    "        img_dir=judge_img_dir,\n",
    "        transform=get_val_transforms()\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            if outputs.ndim == 0:\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            outputs = outputs.cpu().numpy()\n",
    "            predictions.extend(outputs.tolist())\n",
    "\n",
    "    predictions = [round(p, 1) for p in predictions]\n",
    "\n",
    "    print(\"🔍 Sample Predictions:\")\n",
    "    print(predictions[:10])\n",
    "    return predictions\n",
    "\n",
    "def main():\n",
    "    print(\"🔧 Starting main pipeline...\")\n",
    "\n",
    "    root = setup_kaggle_dataset()\n",
    "    cleaned_csv = root / \"wiki_labels_clean.csv\"\n",
    "    img_dir = root / \"wiki_labeled/wiki_labeled\"\n",
    "    checkpoint_root = root / \"output/checkpoints\"\n",
    "    checkpoint = checkpoint_root / \"resnet_final_model.pth\"\n",
    "\n",
    "    print(\"🎯 Starting hyperparameter tuning...\")\n",
    "    hyperparameter_tuning(\n",
    "        cleaned_csv=cleaned_csv,\n",
    "        img_dir=img_dir,\n",
    "        checkpoint_root=checkpoint_root\n",
    "    )\n",
    "    print(\"🧠 Starting final training...\")\n",
    "    final_rmse = train_model(\n",
    "        csv_path=str(cleaned_csv),\n",
    "        img_dir=str(img_dir),\n",
    "        epochs=25,\n",
    "        batch_size=8,\n",
    "        lr=1e-3,\n",
    "        checkpoint_path=str(checkpoint)\n",
    "    )\n",
    "    print(f\"✅ Final model RMSE: {final_rmse}\")\n",
    "\n",
    "    print(\" Running final inference on Judge set for report...\")\n",
    "    judge_csv = root / \"wiki_judge.csv\"\n",
    "    judge_img_dir = root / \"wiki_judge_images/wiki_judge_images\"\n",
    "\n",
    "    predictions = run_inference_for_report(\n",
    "        judge_csv=judge_csv,\n",
    "        judge_img_dir=judge_img_dir,\n",
    "        checkpoint_path=str(checkpoint)\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Sample predictions to include in report:\")\n",
    "    print(predictions[:10])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332262b-520d-4100-a132-5026468d23e4",
   "metadata": {},
   "source": [
    "## Conclusion ##\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afc7fd-6776-4617-b080-a20f781cd098",
   "metadata": {},
   "source": [
    "This project successfully developed a robust deep learning model for age prediction from facial images, demonstrating significant performance improvements through systematic experimentation and optimization. Starting with a baseline CNN model that yielded poor results (RMSE = 6051, R² -2.02), we achieved a 70%reduction in error (RMSE = 7.5) and strong correlation (R² 0.79) by implementing several key optimizations. The transition to ResNet50 for feature extraction, combined with comprehensive data augmentation techniques including RGB conversion, resizing, and flipping, stabilized predictions and reduced RMSE to 16.11. Further refinements through hyperparameter tuning and the adoption of Smooth L1 Loss enhanced model robustness and generalization. Cross-validation and early stopping ensured reliability, while test-set inference confirmed the model's effectiveness on unseen data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "1.\tHe, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 770-778).\n",
    "2.\tKrizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet Classification with Deep Convolutional Neural Networks. Communications of the ACM, 60(6), 84-90.\n",
    "3.\tGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\n",
    "4.\tHoward, J., & Gugger, S. (2020). Fastai: A Layered API for Deep Learning. Information, 11(2), 108.\n",
    "5.\tRay Tune Documentation: https://docs.ray.io/en/latest/tune/index.html\n",
    "6.\tAshis@CUDenver (2025). Age Prediction (Spring'25 at CU Denver). Retrieved from https://kaggle.com/competitions/age-prediction-spring-25-at-cu-denver. Kaggle."
   ],
   "id": "cb30cd3c2fcf284f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Video Link\n",
    "\n",
    "https://drive.google.com/file/d/1Td7vsG91Uib2_UEnaB695RhOLl7Z5EBn/view?usp=drive_link\n"
   ],
   "id": "d791309881620511"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
